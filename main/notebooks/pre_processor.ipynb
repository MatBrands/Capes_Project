{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import nltk\n",
    "import subprocess\n",
    "# nltk.download('stopwords')\n",
    "from difflib import SequenceMatcher\n",
    "from os import cpu_count\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"my bar!\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013\n",
    "df = pd.read_parquet(f'../datasets/raw/{year}.parquet', engine='pyarrow')\n",
    "df = df[['resumo', 'palavra_chave', 'subareas', 'areas', 'colegios']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.palavra_chave.replace(to_replace = r'1[.]', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r' \\d[.]', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'(\\S{2,})(?:\\.)', value = '\\\\1;', regex=True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'\\b(pt|en)\\b', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r' ,|, | [,] | /|/ | [/] ', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r' [.] |\\(\\d\\)', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r' \\x96 |\\x93', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'[^a-z0-9\\s\\x80-\\xff,.:;?!-]', value = '', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r' - |; | ;|; ;', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r';{2,}', value = ';', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace= r'[\\W_]+$|^[;]+', value='', regex=True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'palavras-chave\\S', value = '', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'^\\s+|\\s+$|\\x80', value = '', regex = True, inplace=True)\n",
    "df.palavra_chave.replace(to_replace = r'[^\\w\\s;]', value = '', regex = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resumo.replace(to_replace= r'[^a-zA-Z0-9\\s]+', value='', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str) -> str:\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    new_text = [item for item in wordpunct_tokenize(text) if item not in stop_words]\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lc_stem(text: str) -> str:\n",
    "    stemmer = LancasterStemmer()\n",
    "    words = [stemmer.stem(word) for word in wordpunct_tokenize(text)]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|██████████| 67534/67534 [00:09<00:00, 7379.67it/s]\n",
      "my bar!: 100%|██████████| 67534/67534 [01:01<00:00, 1105.61it/s]\n",
      "my bar!: 100%|██████████| 67534/67534 [00:00<00:00, 1431565.43it/s]\n",
      "my bar!: 100%|██████████| 67534/67534 [00:03<00:00, 17544.35it/s]\n",
      "my bar!: 100%|██████████| 67534/67534 [00:05<00:00, 13452.53it/s]\n",
      "my bar!: 100%|██████████| 67534/67534 [00:00<00:00, 145350.47it/s]\n"
     ]
    }
   ],
   "source": [
    "df.resumo = df.resumo.progress_apply(remove_stopwords).progress_apply(lc_stem).progress_apply(lambda x: unidecode(x))\n",
    "df.palavra_chave = df.palavra_chave.progress_apply(remove_stopwords).progress_apply(lc_stem).progress_apply(lambda x: unidecode(x))\n",
    "df.palavra_chave.replace(to_replace = r' ; ', value = ';', regex = True, inplace=True)\n",
    "del remove_stopwords, lc_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.query(\"palavra_chave == '' | resumo == ''\").index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = df.palavra_chave.copy()\n",
    "key_words = list(set(';'.join(key_words).split(';')))\n",
    "\n",
    "key_words = [item.replace(r'[^a-zA-Z0-9\\s]+', '') for item in key_words]\n",
    "\n",
    "key_words = [item for item in key_words if 2 < len(item) < 80]\n",
    "key_words = [item for item in key_words if not item.isdigit()]\n",
    "for i, _ in enumerate(key_words):\n",
    "    key_words[i] = key_words[i].strip()\n",
    "\n",
    "key_words = list(set(key_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109190"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()\n",
    "df_test.palavra_chave.replace(r' ', '', regex=True, inplace=True)\n",
    "df_test.resumo.replace(r' ', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [item.replace(' ', '') for item in key_words]\n",
    "\n",
    "test = list(set(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108773"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_or_pertency(sentence: str, text: str) -> str:\n",
    "    if sentence == '' or text == '':\n",
    "        return False\n",
    "    if sentence in text or text in sentence:\n",
    "        return True\n",
    "    \n",
    "    similaridade = SequenceMatcher(lambda x: x == \" \", sentence, text).real_quick_ratio()\n",
    "    similaridade = SequenceMatcher(lambda x: x == \" \", sentence, text).ratio()\n",
    "    similaridade = int(similaridade * 100)\n",
    "    if similaridade > 75: return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_similarity(row, character):\n",
    "    chave = calculate_similarity_or_pertency(character, row['palavra_chave'])\n",
    "    resumo = calculate_similarity_or_pertency(character, row['resumo'])\n",
    "    return chave or resumo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 50 palavras_chave = 1m 1.3s\n",
    "- 500 palavras_chave = 9 24.4s\n",
    "- 5000 palavras_chave = 126m 2.3s\n",
    "- 109190 palavras_chave = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_character(character):    \n",
    "    cut = df[df.apply(lambda row: apply_similarity(row, character), axis=1)]\n",
    "    results = []\n",
    "    for subarea in sorted(cut.subareas.unique()):\n",
    "        new_cut = cut[cut.subareas == subarea]\n",
    "        colegio, area = new_cut.colegios.unique()[0], new_cut.areas.unique()[0]\n",
    "        frequencia = new_cut.palavra_chave.str.count(character).sum() + new_cut.resumo.str.count(character).sum()\n",
    "        if frequencia == 0: frequencia = new_cut.subareas.value_counts()[0]\n",
    "        results.append([colegio, area, subarea, character, frequencia])\n",
    "    \n",
    "    return results\n",
    "\n",
    "max_threads = cpu_count()\n",
    "data = []\n",
    "with multiprocessing.Pool(processes=max_threads) as pool:\n",
    "    for result in pool.imap_unordered(process_character, key_words[:3]):\n",
    "        data.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dtype = {\n",
    "    'colegio': 'category',\n",
    "    'area': 'category',\n",
    "    'subarea': 'category',\n",
    "    'palavra_chave': 'category',\n",
    "    'frequencia': 'uint64'\n",
    "}\n",
    "\n",
    "freq = pd.DataFrame(data, columns=columns_dtype.keys()).astype(columns_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.set_index('palavra_chave').sort_index().sort_values('frequencia', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo = freq.sort_values('frequencia', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
